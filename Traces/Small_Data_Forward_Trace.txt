Welcome to Isaac's Feature Selection Algorithm
Type the name of the file to test: CS170_SMALLtestdata__45.txt

Choose a search algorithm.
        1) Forward Selection
        2) Backward Elimination
1


This dataset has 10 features (not including the class attribute), with 300 instances.

Beginning search.
        Considering feature 1, accuracy is 75.7%
        Considering feature 2, accuracy is 68.7%
        Considering feature 3, accuracy is 72.3%
        Considering feature 4, accuracy is 70.3%
        Considering feature 5, accuracy is 85.7%
        Considering feature 6, accuracy is 68.3%
        Considering feature 7, accuracy is 74.7%
        Considering feature 8, accuracy is 68.0%
        Considering feature 9, accuracy is 70.3%
        Considering feature 10, accuracy is 64.3%
Feature set {5} was best, accuracy is 85.7%
        Considering feature 1, accuracy is 82.3%
        Considering feature 2, accuracy is 87.3%
        Considering feature 3, accuracy is 85.0%
        Considering feature 4, accuracy is 82.0%
        Considering feature 6, accuracy is 85.3%
        Considering feature 7, accuracy is 95.0%
        Considering feature 8, accuracy is 79.7%
        Considering feature 9, accuracy is 83.3%
        Considering feature 10, accuracy is 86.0%
Feature set {5, 7} was best, accuracy is 95.0%
        Considering feature 1, accuracy is 91.3%
        Considering feature 2, accuracy is 90.3%
        Considering feature 3, accuracy is 91.3%
        Considering feature 4, accuracy is 89.7%
        Considering feature 6, accuracy is 93.0%
        Considering feature 8, accuracy is 91.7%
        Considering feature 9, accuracy is 90.0%
        Considering feature 10, accuracy is 95.0%
Feature set {10, 5, 7} was best, accuracy is 95.0%
        Considering feature 1, accuracy is 88.7%
        Considering feature 2, accuracy is 85.0%
        Considering feature 3, accuracy is 91.3%
        Considering feature 4, accuracy is 89.0%
        Considering feature 6, accuracy is 90.0%
        Considering feature 8, accuracy is 86.0%
        Considering feature 9, accuracy is 89.0%
Feature set {10, 3, 5, 7} was best, accuracy is 91.3%
        Considering feature 1, accuracy is 88.3%
        Considering feature 2, accuracy is 85.7%
        Considering feature 4, accuracy is 85.0%
        Considering feature 6, accuracy is 85.7%
        Considering feature 8, accuracy is 82.3%
        Considering feature 9, accuracy is 85.3%
Feature set {1, 3, 5, 7, 10} was best, accuracy is 88.3%
        Considering feature 2, accuracy is 80.3%
        Considering feature 4, accuracy is 80.7%
        Considering feature 6, accuracy is 83.0%
        Considering feature 8, accuracy is 80.7%
        Considering feature 9, accuracy is 82.7%
Feature set {1, 3, 5, 6, 7, 10} was best, accuracy is 83.0%
        Considering feature 2, accuracy is 80.0%
        Considering feature 4, accuracy is 77.0%
        Considering feature 8, accuracy is 79.0%
        Considering feature 9, accuracy is 77.7%
Feature set {1, 2, 3, 5, 6, 7, 10} was best, accuracy is 80.0%
        Considering feature 4, accuracy is 72.7%
        Considering feature 8, accuracy is 75.3%
        Considering feature 9, accuracy is 76.3%
Feature set {1, 2, 3, 5, 6, 7, 9, 10} was best, accuracy is 76.3%
        Considering feature 4, accuracy is 71.7%
        Considering feature 8, accuracy is 72.0%
Feature set {1, 2, 3, 5, 6, 7, 8, 9, 10} was best, accuracy is 72.0%
        Considering feature 4, accuracy is 67.0%
Feature set {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} was best, accuracy is 67.0%

Finished search!! The best feature subset is {5, 7}, which has an accuracy of 95.0%
Time elapsed: 27.1 seconds